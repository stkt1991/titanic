{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library for data analysis, this can be used like excel.(pandas is better for data modification and aggregation)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read the train data and test data\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## try to compare the surviver between male and female\n",
    "#import 2D plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# import statistical data visualization based on matplotlib\n",
    "import seaborn as sns\n",
    "# the function to output graph on jupyternotebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## preprocess the dataset including missing data \n",
    "#  1.Replace missing data with surrogate data\n",
    "#  2.Convert character string categorical data to numbers\n",
    "\n",
    "# Let's clean train dataset. There were missing data in three columns \"Age\", \"Embarked\" and \"Cabin\" in train. \n",
    "# Since \"Cabin\" is too many missing value; therefore I don't use \n",
    "# therefore let's clean up the two missing data \"Age\" and \"Embarked\".\n",
    "# \"Age\", let's simply use the median of all data of train as surrogate data. (It is very important and big discussion as to what to use with surrogate data and what kind of processing to add, but I will think about it simply here)\n",
    "\n",
    "# Next is \"Embarked\" (departure point), but only two missing data are included in the train.\n",
    "# When checking other data, \"S\" was the most frequent value, let's use \"S\" as surrogate data.\n",
    "# fill in surrogate data using fillna () in each column. \n",
    "\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now that the missing data has been processed, \n",
    "# convert the categorical data string to a number next. \n",
    "# Columns that have character strings as values in the items used in this forecast are \"Sex\" and \"Embarked\". \n",
    "# Sex is the two character strings \"male\" and \"female\".\n",
    "# Embarked is three character strings \"S\" \"C\" \"Q\". \n",
    "# Let's convert them to numbers.\n",
    "train[\"Sex\"] = train[\"Sex\"].map({\"male\" : 0, \"female\" : 1})\n",
    "train[\"Embarked\"] = train[\"Embarked\"].map({\"S\" : 0, \"C\" : 1, \"Q\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name  Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    0   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)    1   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    0   \n",
       "3          895       3                              Wirz, Mr. Albert    0   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    1   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin  Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN         2  \n",
       "1  47.0      1      0   363272   7.0000   NaN         0  \n",
       "2  62.0      0      0   240276   9.6875   NaN         2  \n",
       "3  27.0      0      0   315154   8.6625   NaN         0  \n",
       "4  22.0      1      1  3101298  12.2875   NaN         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I converted the missing data of \"Age\" to the median, and the numerical value of the string value (Age and Embarked). \n",
    "# Furthermore, in test, there was only one missing data in \"Fare\", so I used the median (Median) as proxy data. \n",
    "# make sure to check the contents of the data with head ().\n",
    "\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "test[\"Sex\"] = test[\"Sex\"].map({\"male\" : 0, \"female\" : 1})\n",
    "test[\"Embarked\"] = test[\"Embarked\"].map({\"S\" : 0, \"C\" : 1, \"Q\" : 2})\n",
    "test.Fare[152] = test.Fare.median()\n",
    " \n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete column we don't need\n",
    "train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomforest model\n",
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get the value of objective valuable and explanatory variable of \"train\" data\n",
    "# use 7 valuables as well as other methods\n",
    "target = train[\"Survived\"].values\n",
    "features = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# model is random forest(use default parameter)\n",
    "forest = RandomForestClassifier(n_estimators = 10)\n",
    "forest = forest.fit(features, target)\n",
    "\n",
    "# retrive the valuable from test\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# make prediction and write to csv\n",
    "my_prediction_forest = forest.predict(test_features)\n",
    "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution_forest = pd.DataFrame(my_prediction_forest, PassengerId, columns=[\"Survived\"])\n",
    "my_solution_forest.to_csv(\"my_tree5.csv\", index_label=[\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient boosting model\n",
    "# import random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# get the value of target valuable and explanatory variable of \"train\"\n",
    "# use 7 valuables as well as other methods\n",
    "target = train[\"Survived\"].values\n",
    "features = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# model is random forest with gradientbooting classiier â€»parameter is default.\n",
    "forest = GradientBoostingClassifier(n_estimators = 10)\n",
    "forest = forest.fit(features, target)\n",
    "\n",
    "# retrive the valuable from test\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# make prediction and write to csv\n",
    "my_prediction_forest = forest.predict(test_features)\n",
    "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution_forest = pd.DataFrame(my_prediction_forest, PassengerId, columns=[\"Survived\"])\n",
    "my_solution_forest.to_csv(\"my_tree6.csv\", index_label=[\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
